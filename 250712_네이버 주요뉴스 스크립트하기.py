import time
import os
import requests
import logging
from bs4 import BeautifulSoup
from datetime import datetime

# ====================== ì„¤ì • ======================
DISCORD_WEBHOOK_URL = os.getenv("DISCORD_WEBHOOK_URL")
TRACK_KEYWORDS = ["íŠ¹ì§•ì£¼", "ì •ë¶€", "ê¸ˆë¦¬", "í™˜ìœ¨", "ê³µë§¤ë„", "ë¬¼ê°€"]
SENT_LINKS_FILE = "sent_links.txt"

NEWS_SITES = {
    "ë„¤ì´ë²„": "https://finance.naver.com/news/mainnews.naver",
    "ì´íˆ¬ë°ì´": "https://rss.etoday.co.kr/eto/etoday_news_all.xml",
    "í•œêµ­ê²½ì œ": "https://www.hankyung.com/feed/all-news",
    "ë§¤ì¼ê²½ì œ": "https://www.mk.co.kr/rss/40300001/",
    "ì—°í•©ë‰´ìŠ¤": "https://www.yna.co.kr/rss/news.xml",
    "ì„œìš¸ê²½ì œ": "https://www.sedaily.com/rss/news",
    "íŒìŠ¤ë„·": "https://www.paxnet.co.kr/news/all?newsSetId=4667&objId=N4667&wlog_rpax=GNB_newsist",

    # ì¶”ê°€ ê°€ëŠ¥
}

# ====================== ë¡œê¹… ì„¤ì • ======================
logging.basicConfig(filename='news_monitor.log', level=logging.INFO,
                    format='%(asctime)s - %(levelname)s - %(message)s')

# ====================== ì „ì†¡ ì´ë ¥ ë¡œë”© ======================
def load_sent_links():
    try:
        with open(SENT_LINKS_FILE, "r") as f:
            return set(f.read().splitlines())
    except FileNotFoundError:
        return set()

def save_sent_link(link):
    with open(SENT_LINKS_FILE, "a") as f:
        f.write(link + "\n")

sent_news_links = load_sent_links()

# ====================== í¬ë¡¤ë§ í•¨ìˆ˜ ======================
def get_news_naver():
    url = NEWS_SITES["ë„¤ì´ë²„"]
    headers = {"User-Agent": "Mozilla/5.0"}
    resp = requests.get(url, headers=headers)
    soup = BeautifulSoup(resp.text, "html.parser")
    news_items = soup.select(".mainNewsList > li")
    results = []
    for item in news_items:
        tag = item.select_one("a")
        if tag and tag.has_attr("href"):
            title = tag.get_text(strip=True)
            link = "https://finance.naver.com" + tag["href"]
            results.append((title, link))
    return results

def get_news_paxnet():
    url = NEWS_SITES["íŒìŠ¤ë„·"]
    headers = {"User-Agent": "Mozilla/5.0"}
    resp = requests.get(url, headers=headers)
    soup = BeautifulSoup(resp.text, "html.parser")
    news_items = soup.select(".news_list ul li a")
    results = []
    for tag in news_items:
        title = tag.get_text(strip=True)
        link = tag["href"]
        if not link.startswith("http"):
            link = "https://www.paxnet.co.kr" + link
        results.append((title, link))
    return results

def safe_crawl(func, name):
    try:
        return func()
    except Exception as e:
        logging.error(f"[{name}] í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
        return []

def get_all_news():
    news = []
    news.extend(safe_crawl(get_news_naver, "ë„¤ì´ë²„"))
    news.extend(safe_crawl(get_news_paxnet, "íŒìŠ¤ë„·"))
    return news

# ====================== í•„í„° & í¬ë§· ======================
def filter_news_by_keywords(news_list, keywords):
    filtered = []
    for title, link in news_list:
        for kw in keywords:
            if kw in title:
                filtered.append((kw, title, link))
                break
    return filtered

def format_news_message(title, link):
    today = datetime.now().strftime("%Y.%m.%d")
    return f"ğŸ“… ë‚ ì§œ: {today}\nğŸ“° ì£¼ìš” ë‰´ìŠ¤: {title}\nğŸ”— {link}"

def format_keyword_news_message(keyword, title, link):
    today = datetime.now().strftime("%Y.%m.%d")
    template = {
        "íŠ¹ì§•ì£¼": ("ğŸ”¥", "- ì˜¤ëŠ˜ì˜ íŠ¹ì§•ì£¼ ê´€ë ¨ ê¸°ì‚¬ì…ë‹ˆë‹¤.\n- ë³€ë™ì„± ì£¼ì˜", "ì£¼ê°€ ë‹¨ê¸° ê¸‰ë“±/ê¸‰ë½ ê°€ëŠ¥ì„±"),
        "ì •ë¶€": ("ğŸ›ï¸", "- ì •ë¶€ ì •ì±… ë˜ëŠ” ë°œí‘œ ê´€ë ¨ ê¸°ì‚¬ì…ë‹ˆë‹¤.\n- ì •ì±… ìˆ˜í˜œì£¼ ì£¼ëª©", "ì •ì±… ê´€ë ¨ ì¢…ëª©ì— ì˜í–¥ ì˜ˆìƒ"),
        "ê¸ˆë¦¬": ("ğŸ’°", "- ê¸ˆë¦¬ ë³€ë™ ê´€ë ¨ ë‰´ìŠ¤ì…ë‹ˆë‹¤.\n- ê¸ˆìœµì‹œì¥ ì˜í–¥ ì£¼ëª©", "ëŒ€ì¶œ, íˆ¬ìì— ì˜í–¥ ê°€ëŠ¥ì„±"),
        "í™˜ìœ¨": ("ğŸ’±", "- í™˜ìœ¨ ë³€ë™ ê´€ë ¨ ê¸°ì‚¬ì…ë‹ˆë‹¤.\n- ìˆ˜ì¶œì… ê¸°ì—… ì˜í–¥ ì£¼ëª©", "ìˆ˜ì¶œì… ì‹¤ì  ë³€ë™ ê°€ëŠ¥ì„±"),
        "ê³µë§¤ë„": ("ğŸ“‰", "- ê³µë§¤ë„ ê´€ë ¨ ë‰´ìŠ¤ì…ë‹ˆë‹¤.\n- ì‹œì¥ ë³€ë™ì„± ì£¼ì˜", "ë‹¨ê¸° ì£¼ê°€ ë³€ë™ ê°€ëŠ¥ì„±"),
        "ë¬¼ê°€": ("ğŸ“ˆ", "- ë¬¼ê°€ ìƒìŠ¹ ë° ê²½ì œ ìƒí™© ë‰´ìŠ¤ì…ë‹ˆë‹¤.\n- ì†Œë¹„ì ë¬¼ê°€ ì§€ìˆ˜ ì£¼ëª©", "ì†Œë¹„ì‹¬ë¦¬ ë° ê¸ˆë¦¬ ì˜í–¥ ê°€ëŠ¥ì„±")
    }
    emoji, core, impact = template.get(keyword, ("ğŸ“Œ", "- ì¤‘ìš” ë‰´ìŠ¤ì…ë‹ˆë‹¤.", "ì‹œì¥ ì „ë°˜ì— ì˜í–¥ ê°€ëŠ¥ì„±"))
    return (
        f"ğŸ“… ë‚ ì§œ: {today}\n"
        f"{emoji} `{keyword}` ê´€ë ¨ ë‰´ìŠ¤: {title}\n"
        f"ğŸ“Š í•µì‹¬ ë‚´ìš©:\n{core}\n"
        f"ğŸ“ˆ ì˜í–¥ ì˜ˆìƒ: {impact}\n"
        f"ğŸ”— {link}"
    )

# ====================== ë””ìŠ¤ì½”ë“œ ì „ì†¡ ======================
def send_to_discord(message):
    data = {"content": message}
    try:
        resp = requests.post(DISCORD_WEBHOOK_URL, json=data)
        if resp.status_code != 204:
            logging.error(f"âŒ ë””ìŠ¤ì½”ë“œ ì „ì†¡ ì‹¤íŒ¨: {resp.status_code} {resp.text}")
            return False
        return True
    except Exception as e:
        logging.error(f"âŒ ë””ìŠ¤ì½”ë“œ ìš”ì²­ ì˜ˆì™¸: {e}")
        return False

# ====================== ë©”ì¸ ë£¨í”„ ======================
def monitor_news(interval=60):
    print("ğŸ” ë‰´ìŠ¤ ëª¨ë‹ˆí„°ë§ ì‹œì‘ (CTRL+Cë¡œ ì¢…ë£Œ)")
    while True:
        try:
            news_list = get_all_news()
            for title, link in news_list:
                if link not in sent_news_links:
                    msg = format_news_message(title, link)
                    if send_to_discord(msg):
                        print(f"ğŸ“¤ ê¸°ë³¸ ë‰´ìŠ¤ ì „ì†¡: {title}")
                        sent_news_links.add(link)
                        save_sent_link(link)

            keyword_news = filter_news_by_keywords(news_list, TRACK_KEYWORDS)
            for keyword, title, link in keyword_news:
                if link not in sent_news_links:
                    msg = format_keyword_news_message(keyword, title, link)
                    if send_to_discord(msg):
                        print(f"ğŸ“Œ í‚¤ì›Œë“œ[{keyword}] ë‰´ìŠ¤ ì „ì†¡: {title}")
                        sent_news_links.add(link)
                        save_sent_link(link)

            time.sleep(interval)
        except Exception as e:
            logging.error(f"ë£¨í”„ ì¤‘ ì—ëŸ¬: {e}")
            time.sleep(interval)

# ====================== ì‹¤í–‰ ======================
if __name__ == "__main__":
    try:
        monitor_news(interval=30)
    except KeyboardInterrupt:
        print("\nğŸ›‘ ëª¨ë‹ˆí„°ë§ ì¢…ë£Œë¨")
